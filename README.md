# Tiny Diffusion â€” A Minimal Denoising Diffusion Model

A clean, minimal PyTorch implementation of a **Denoising Diffusion Probabilistic Model (DDPM)**, training on CIFAR-10 to generate 32Ã—32 images.  
Itâ€™s compact enough to study in a weekend, but powerful enough to produce compelling results.


---

## Features

- **UNet-style architecture** for noise prediction
- **Cosine Î²-schedule** for smoother training
- **Automatic Mixed Precision (AMP)** for faster training
- **Checkpointing** & sample grids during training
- **From-scratch scheduler** (no HuggingFace dependencies)
- **Gradio web demo** to generate images interactively
- Well-structured repo for easy extension (EMA, CFG, conditioning, etc.)

---

## ðŸ“‚ Project Structure

```
tiny-diffusion-neural-network/
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ config.yaml                # Training hyperparameters
â”œâ”€ data/                      # Auto-downloaded CIFAR-10
â”œâ”€ models/
â”‚  â””â”€ unet.py                  # UNet noise predictor
â”œâ”€ diffusion/
â”‚  â”œâ”€ scheduler.py             # Î²-schedule and constants
â”‚  â””â”€ ddpm.py                   # Forward/reverse processes
â”œâ”€ train.py                    # Main training loop
â”œâ”€ sample.py                   # Generate from trained model
â””â”€ app.py                      # Gradio interface
```

---

## Quickstart

### 1) Install dependencies
```bash
python -m venv .venv
source .venv/bin/activate      # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Train the model
```bash
python train.py
```
> CIFAR-10 will download automatically. Training takes ~1â€“4 hours on a modern GPU.  
> Samples are saved in `runs/default/` every few epochs.

### 3) Generate samples
```bash
python sample.py
```
Outputs `samples.png` with an image grid.

### 4) Launch the web demo
```bash
python app.py
```
Visit the Gradio link to interactively generate images.

---

## Configuration

All training parameters are in `config.yaml`:

```yaml
seed: 1337
device: "cuda"
image_size: 32
channels: 3
dataset: "CIFAR10"
batch_size: 128
steps: 1000
beta_schedule: "cosine"
lr: 2.0e-4
epochs: 60
amp: true
samples_per_grid: 64
out_dir: "runs/default"
```






